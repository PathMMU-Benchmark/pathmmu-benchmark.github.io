{"version":3,"file":"js/app.eb6ae504.js","mappings":"qFAAIA,EAAS,WAAkB,IAAIC,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,MAAM,CAACE,MAAM,CAAC,GAAK,QAAQ,CAACF,EAAG,gBAAgB,EACrH,EACIG,EAAkB,G,UCDlBC,EAAS,CAAC,EAKVC,GAAY,OACdD,EACAP,EACAM,GACA,EACA,KACA,KACA,MAIF,EAAeE,EAAiB,Q,UCjB5B,EAAS,WAAkB,IAAIP,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,MAAM,CAACM,YAAY,kCAAkC,CAACN,EAAG,UAAU,CAACO,IAAI,YAAYP,EAAG,YAAYA,EAAG,mBAAmBA,EAAG,aAAaA,EAAG,eAAe,EACjO,EACI,EAAkB,GCFlB,EAAS,WAAkB,IAAIF,EAAIC,KAAQD,EAAIG,MAAMD,GAAG,OAAOF,EAAIU,GAAG,EAC1E,EACI,EAAkB,CAAC,WAAY,IAAIV,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,MAAM,CAACM,YAAY,8EAA8E,CAACN,EAAG,MAAM,CAACM,YAAY,SAAS,CAACR,EAAIW,GAAG,0DAA0DT,EAAG,MAAMA,EAAG,MAAM,CAACM,YAAY,SAASR,EAAIW,GAAG,oDAAoDT,EAAG,MAAM,CAACM,YAAY,QAAQ,CAACR,EAAIW,GAAG,yFAAyFT,EAAG,MAAM,CAACM,YAAY,eAAe,CAACR,EAAIW,GAAG,oCAAoCT,EAAG,MAAMF,EAAIW,GAAG,uEAAuET,EAAG,MAAMF,EAAIW,GAAG,mDAAmDT,EAAG,MAAM,CAACM,YAAY,gBAAgB,CAACR,EAAIW,GAAG,0FAA0FT,EAAG,MAAMF,EAAIW,GAAG,uDAAuDT,EAAG,MAAM,CAACM,YAAY,QAAQ,CAACN,EAAG,MAAM,CAACF,EAAIW,GAAG,wBAAwBT,EAAG,MAAM,CAACF,EAAIW,GAAG,wBAAwBT,EAAG,IAAI,CAACM,YAAY,gBAAgBJ,MAAM,CAAC,KAAO,KAAK,CAACJ,EAAIW,GAAG,6BAA6BX,EAAIW,GAAG,MAAMT,EAAG,IAAI,CAACM,YAAY,gBAAgBJ,MAAM,CAAC,KAAO,KAAK,CAACJ,EAAIW,GAAG,gDAAgDT,EAAG,MAAM,CAACM,YAAY,kDAAkD,CAACN,EAAG,MAAM,CAACM,YAAY,6CAA6CI,YAAY,CAAC,WAAa,YAAY,CAACZ,EAAIW,GAAG,aAAaT,EAAG,MAAM,CAACM,YAAY,6CAA6CI,YAAY,CAAC,WAAa,YAAY,CAACZ,EAAIW,GAAG,gBAAgBT,EAAG,MAAM,CAACM,YAAY,6CAA6CI,YAAY,CAAC,WAAa,YAAY,CAACZ,EAAIW,GAAG,eAAeT,EAAG,MAAM,CAACM,YAAY,6CAA6CI,YAAY,CAAC,WAAa,YAAY,CAACZ,EAAIW,GAAG,YAAYT,EAAG,MAAM,CAACM,YAAY,6CAA6CI,YAAY,CAAC,WAAa,YAAY,CAACZ,EAAIW,GAAG,mBAAmBT,EAAG,MAAM,CAACM,YAAY,6CAA6CI,YAAY,CAAC,WAAa,YAAY,CAACZ,EAAIW,GAAG,cAAcT,EAAG,MAAM,CAACM,YAAY,6CAA6CI,YAAY,CAAC,WAAa,YAAY,CAACZ,EAAIW,GAAG,eAAeT,EAAG,MAAM,CAACM,YAAY,6CAA6CI,YAAY,CAAC,WAAa,YAAY,CAACZ,EAAIW,GAAG,kBAAkBT,EAAG,MAAM,CAACM,YAAY,uBAAuB,CAACN,EAAG,MAAM,CAACE,MAAM,CAAC,IAAM,oCAAoC,IAAM,MAAMF,EAAG,MAAM,CAACM,YAAY,2BAA2B,CAACR,EAAIW,GAAG,2gDAA2gDT,EAAG,MAAM,CAACM,YAAY,sBAAsB,CAACN,EAAG,MAAM,CAACM,YAAY,uBAAuB,CAACR,EAAIW,GAAG,kBAAkBT,EAAG,MAAM,CAACM,YAAY,8BAA8B,CAACR,EAAIW,GAAG,kWACtqI,GC4HA,GACE,IAAAE,GACE,MAAO,CACLC,UAAW,YACXC,QAAS,CACP,CAAEC,QAAS,OAAQC,GAAI,GAEvB,CAAED,QAAS,QAASC,GAAI,GACxB,CAAED,QAAS,UAAWC,GAAI,IAGhC,GC1IkI,ICQhI,GAAY,OACd,EACA,EACA,GACA,EACA,KACA,WACA,MAIF,EAAe,EAAiB,QCnB5B,EAAS,WAAkB,IAAIjB,EAAIC,KAAQD,EAAIG,MAAMD,GAAG,OAAOF,EAAIU,GAAG,EAC1E,EACI,EAAkB,CAAC,WAAY,IAAIV,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,MAAM,CAACM,YAAY,0BAA0B,CAACN,EAAG,MAAM,CAACM,YAAY,sEAAsE,CAACR,EAAIW,GAAG,yBAAyBT,EAAG,MAAM,CAACM,YAAY,yDAAyD,CAACN,EAAG,MAAM,CAACM,YAAY,oCAAoC,CAACR,EAAIW,GAAG,cAAcT,EAAG,MAAM,CAACM,YAAY,2BAA2B,CAACN,EAAG,MAAM,CAACM,YAAY,gBAAgB,CAACR,EAAIW,GAAG,ksBAAksBT,EAAG,MAAM,CAACM,YAAY,cAAcJ,MAAM,CAAC,IAAM,oCAAoC,IAAM,MAAMF,EAAG,WAAWA,EAAG,MAAM,CAACM,YAAY,oBAAoBI,YAAY,CAAC,OAAS,WAAW,CAACV,EAAG,MAAM,CAACM,YAAY,gBAAgB,CAACR,EAAIW,GAAG,kBAAkBT,EAAG,MAAM,CAACM,YAAY,yCAAyC,CAACN,EAAG,MAAM,CAACA,EAAG,MAAM,CAACM,YAAY,YAAY,CAACR,EAAIW,GAAG,iBAAiBT,EAAG,MAAM,CAACM,YAAY,wBAAwB,CAACR,EAAIW,GAAG,gJAAgJT,EAAG,MAAM,CAACA,EAAG,MAAM,CAACM,YAAY,YAAY,CAACR,EAAIW,GAAG,iBAAiBT,EAAG,MAAM,CAACM,YAAY,wBAAwB,CAACR,EAAIW,GAAG,gJAAgJT,EAAG,MAAM,CAACA,EAAG,MAAM,CAACM,YAAY,YAAY,CAACR,EAAIW,GAAG,iBAAiBT,EAAG,MAAM,CAACM,YAAY,wBAAwB,CAACR,EAAIW,GAAG,gJAAgJT,EAAG,MAAM,CAACA,EAAG,MAAM,CAACM,YAAY,YAAY,CAACR,EAAIW,GAAG,iBAAiBT,EAAG,MAAM,CAACM,YAAY,wBAAwB,CAACR,EAAIW,GAAG,gJAAgJT,EAAG,MAAM,CAACA,EAAG,MAAM,CAACM,YAAY,YAAY,CAACR,EAAIW,GAAG,iBAAiBT,EAAG,MAAM,CAACM,YAAY,wBAAwB,CAACR,EAAIW,GAAG,gJAAgJT,EAAG,MAAM,CAACA,EAAG,MAAM,CAACM,YAAY,YAAY,CAACR,EAAIW,GAAG,iBAAiBT,EAAG,MAAM,CAACM,YAAY,wBAAwB,CAACR,EAAIW,GAAG,oJAAoJT,EAAG,MAAM,CAACM,YAAY,oBAAoBI,YAAY,CAAC,OAAS,WAAW,CAACV,EAAG,MAAM,CAACM,YAAY,wCAAwC,CAACR,EAAIW,GAAG,iBAAiBT,EAAG,KAAK,CAACA,EAAG,KAAK,CAACF,EAAIW,GAAG,6GAA6GT,EAAG,KAAK,CAACF,EAAIW,GAAG,sJAAsJT,EAAG,KAAK,CAACF,EAAIW,GAAG,0EAA4ET,EAAG,KAAK,CAACF,EAAIW,GAAG,uFAAyFT,EAAG,MAAM,CAACM,YAAY,oBAAoBI,YAAY,CAAC,OAAS,WAAW,CAACV,EAAG,MAAM,CAACM,YAAY,iBAAiB,CAACR,EAAIW,GAAG,kBAAkBT,EAAG,MAAM,CAACM,YAAY,qBAAqB,CAACN,EAAG,MAAM,CAACE,MAAM,CAAC,IAAM,wCAAwC,IAAM,MAAMF,EAAG,MAAM,CAACM,YAAY,QAAQ,CAACN,EAAG,MAAM,CAACM,YAAY,SAAS,CAACR,EAAIW,GAAG,4NAA4NT,EAAG,MAAM,CAACM,YAAY,QAAQ,CAACN,EAAG,IAAI,CAACM,YAAY,gBAAgBJ,MAAM,CAAC,KAAO,KAAK,CAACJ,EAAIW,GAAG,YAAYT,EAAG,IAAI,CAACM,YAAY,gBAAgBJ,MAAM,CAAC,KAAO,KAAK,CAACJ,EAAIW,GAAG,aAAaT,EAAG,IAAI,CAACM,YAAY,gBAAgBJ,MAAM,CAAC,KAAO,KAAK,CAACJ,EAAIW,GAAG,oBAAoBT,EAAG,MAAM,CAACM,YAAY,sBAAsB,CAACN,EAAG,IAAI,CAACF,EAAIW,GAAG,gEAAgET,EAAG,MAAM,CAACM,YAAY,yDAAyD,CAACN,EAAG,MAAM,CAACM,YAAY,oCAAoC,CAACR,EAAIW,GAAG,4CAA4CT,EAAG,MAAM,CAACM,YAAY,2BAA2B,CAACN,EAAG,MAAM,CAACM,YAAY,gBAAgB,CAACR,EAAIW,GAAG,ksBAAksBT,EAAG,MAAM,CAACM,YAAY,aAAaJ,MAAM,CAAC,IAAM,4CAA4C,IAAM,MAAMF,EAAG,MAAM,CAACM,YAAY,cAAc,CAACR,EAAIW,GAAG,uIAC3uL,GC6JA,GAAiB,EChKoH,ICQjI,GAAY,OACd,EACA,EACA,GACA,EACA,KACA,WACA,MAIF,EAAe,EAAiB,QCnB5B,EAAS,WAAkB,IAAIX,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,MAAM,CAACM,YAAY,6BAA6B,CAACN,EAAG,MAAM,CAACM,YAAY,sEAAsE,CAACR,EAAIW,GAAG,0BAA0BX,EAAIU,GAAG,GAAGR,EAAG,MAAM,CAACM,YAAY,kDAAkD,CAACN,EAAG,MAAM,CAACM,YAAY,OAAOI,YAAY,CAAC,MAAQ,UAAU,CAACV,EAAG,MAAM,CAACM,YAAY,SAAS,CAACN,EAAG,KAAK,CAACU,YAAY,CAAC,cAAc,SAAS,CAACV,EAAG,KAAK,CAACM,YAAY,QAAQR,EAAIkB,GAAIlB,EAAU,QAAE,SAASmB,EAAKC,GAAO,OAAOlB,EAAG,KAAK,CAACmB,IAAID,EAAMZ,YAAY,OAAO,CAAW,GAATY,EAAYlB,EAAG,MAAM,CAACA,EAAG,IAAI,CAACF,EAAIW,GAAG,gBAAgBT,EAAG,IAAI,CAACF,EAAIW,GAAG,cAAc,GAAGT,EAAG,MAAM,CAACA,EAAG,IAAI,CAACF,EAAIW,GAAGX,EAAIsB,GAAGH,SAAY,KAAI,GAAGjB,EAAG,KAAK,CAACU,YAAY,CAAC,iBAAiB,SAAS,CAACV,EAAG,KAAK,CAACM,YAAY,QAAQR,EAAIkB,GAAIlB,EAAU,QAAE,SAASmB,EAAKC,GAAO,OAAOlB,EAAG,KAAK,CAACmB,IAAID,EAAMZ,YAAY,OAAO,CAAcN,EAAG,MAAN,GAATkB,EAAqB,CAACpB,EAAIU,GAAG,GAAE,IAAiB,CAACR,EAAG,MAAM,CAACM,YAAY,QAAQ,CAACN,EAAG,MAAM,CAACM,YAAY,WAAW,CAACN,EAAG,IAAI,CAACF,EAAIW,GAAG,UAAUT,EAAG,IAAI,CAACM,YAAY,UAAUI,YAAY,CAAC,cAAc,QAAQ,CAACZ,EAAIW,GAAG,MAAMX,EAAIsB,GAAGtB,EAAIuB,QAAQH,GAAOI,IAAI,WAAWtB,EAAG,MAAM,CAACM,YAAY,WAAW,CAACN,EAAG,IAAI,CAACF,EAAIW,GAAG,SAAST,EAAG,IAAI,CAACM,YAAY,UAAUI,YAAY,CAAC,cAAc,QAAQ,CAACZ,EAAIW,GAAG,MAAMX,EAAIsB,GAAGtB,EAAIuB,QAAQH,GAAOK,IAAI,gBAAgB,KAAI,GAAGvB,EAAG,MAAM,CAACM,YAAY,WAAWR,EAAIkB,GAAIlB,EAAU,QAAE,SAASmB,GAAM,OAAOjB,EAAG,KAAK,CAACmB,IAAIF,EAAKO,KAAKlB,YAAY,SAAS,CAACN,EAAG,KAAK,CAACM,YAAY,OAAO,CAACN,EAAG,IAAI,CAACE,MAAM,CAAC,KAAOe,EAAKQ,KAAK,OAAS,WAAW,CAAC3B,EAAIW,GAAGX,EAAIsB,GAAGH,EAAKO,WAAW1B,EAAIkB,GAAIC,EAAS,MAAE,SAASS,EAAEC,GAAG,OAAO3B,EAAG,KAAK,CAACmB,IAAIQ,EAAErB,YAAY,OAAO,CAAUN,EAAG,MAAN,GAAL2B,EAAiB,CAAC3B,EAAG,MAAM,CAACM,YAAY,WAAW,CAACN,EAAG,IAAI,CAACF,EAAIW,GAAGX,EAAIsB,GAAGH,EAAKW,aAAuB,CAAC5B,EAAG,MAAM,CAACM,YAAY,QAAQ,CAACN,EAAG,MAAM,CAACM,YAAY,WAAW,CAACN,EAAG,IAAI,CAACF,EAAIW,GAAGX,EAAIsB,GAAGH,EAAKN,KAAKgB,GAAGL,SAAStB,EAAG,MAAM,CAACM,YAAY,WAAW,CAACN,EAAG,IAAI,CAACF,EAAIW,GAAGX,EAAIsB,GAAGH,EAAKN,KAAKgB,GAAGJ,cAAc,KAAI,EAAE,IAAG,GAAGvB,EAAG,MAAM,CAACM,YAAY,WAAW,CAACR,EAAIW,GAAG,6DAA6DT,EAAG,MAAM,CAACM,YAAY,WAAWR,EAAIkB,GAAIlB,EAAU,QAAE,SAASmB,GAAM,OAAOjB,EAAG,KAAK,CAACmB,IAAIF,EAAKO,KAAKlB,YAAY,SAAS,CAACN,EAAG,KAAK,CAACM,YAAY,OAAO,CAACN,EAAG,IAAI,CAACE,MAAM,CAAC,KAAOe,EAAKQ,KAAK,OAAS,WAAW,CAAC3B,EAAIW,GAAGX,EAAIsB,GAAGH,EAAKO,WAAW1B,EAAIkB,GAAIC,EAAS,MAAE,SAASS,EAAEC,GAAG,OAAO3B,EAAG,KAAK,CAACmB,IAAIQ,EAAErB,YAAY,OAAO,CAAUN,EAAG,MAAN,GAAL2B,EAAiB,CAAC3B,EAAG,MAAM,CAACM,YAAY,WAAW,CAACN,EAAG,IAAI,CAACF,EAAIW,GAAGX,EAAIsB,GAAGH,EAAKW,aAAuB,CAAC5B,EAAG,MAAM,CAACM,YAAY,QAAQ,CAACN,EAAG,MAAM,CAACM,YAAY,WAAW,CAACN,EAAG,IAAI,CAACF,EAAIW,GAAGX,EAAIsB,GAAGH,EAAKN,KAAKgB,GAAGL,SAAStB,EAAG,MAAM,CAACM,YAAY,WAAW,CAACN,EAAG,IAAI,CAACF,EAAIW,GAAGX,EAAIsB,GAAGH,EAAKN,KAAKgB,GAAGJ,cAAc,KAAI,EAAE,IAAG,GAAGvB,EAAG,MAAM,CAACM,YAAY,WAAW,CAACR,EAAIW,GAAG,wDAAwDT,EAAG,MAAM,CAACM,YAAY,WAAWR,EAAIkB,GAAIlB,EAAU,QAAE,SAASmB,GAAM,OAAOjB,EAAG,KAAK,CAACmB,IAAIF,EAAKO,KAAKlB,YAAY,SAAS,CAACN,EAAG,KAAK,CAACM,YAAY,OAAO,CAACN,EAAG,IAAI,CAACE,MAAM,CAAC,KAAOe,EAAKQ,KAAK,OAAS,WAAW,CAAC3B,EAAIW,GAAGX,EAAIsB,GAAGH,EAAKO,WAAW1B,EAAIkB,GAAIC,EAAS,MAAE,SAASS,EAAEC,GAAG,OAAO3B,EAAG,KAAK,CAACmB,IAAIQ,EAAErB,YAAY,OAAO,CAAUN,EAAG,MAAN,GAAL2B,EAAiB,CAAC3B,EAAG,MAAM,CAACM,YAAY,WAAW,CAACN,EAAG,IAAI,CAACF,EAAIW,GAAGX,EAAIsB,GAAGH,EAAKW,aAAuB,CAAC5B,EAAG,MAAM,CAACM,YAAY,QAAQ,CAACN,EAAG,MAAM,CAACM,YAAY,WAAW,CAACN,EAAG,IAAI,CAACF,EAAIW,GAAGX,EAAIsB,GAAGH,EAAKN,KAAKgB,GAAGL,SAAStB,EAAG,MAAM,CAACM,YAAY,WAAW,CAACN,EAAG,IAAI,CAACF,EAAIW,GAAGX,EAAIsB,GAAGH,EAAKN,KAAKgB,GAAGJ,cAAc,KAAI,EAAE,IAAG,UAChzG,EACI,EAAkB,CAAC,WAAY,IAAIzB,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,MAAM,CAACM,YAAY,6CAA6C,CAACN,EAAG,MAAM,CAACM,YAAY,wCAAwC,CAACR,EAAIW,GAAG,iBAAiBT,EAAG,MAAM,CAACM,YAAY,yCAAyC,CAACR,EAAIW,GAAG,ilBACzS,EAAE,WAAY,IAAIX,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,MAAM,CAACM,YAAY,WAAW,CAACN,EAAG,IAAI,CAACF,EAAIW,GAAG,OAAOT,EAAG,IAAI,CAACM,YAAY,UAAUI,YAAY,CAAC,cAAc,QAAQ,CAACZ,EAAIW,GAAG,cACnL,GCsJA,GACE,IAAAE,GACE,MAAO,CACLkB,QAAS,CACP,qBACA,eACA,eACA,UACA,UACA,QAEFC,UAAW,CAET,CAAC,gBAAiB,KAAM,KAAM,KAAM,KAAM,KAAM,MAChD,CAAC,kBAAmB,KAAM,KAAM,KAAM,KAAM,KAAM,OAGpDC,OAAQ,CACN,aACA,eACA,eACA,UACA,UACA,QAEFV,QAAS,CACP,CACEC,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,OAGRS,OAAQ,CACN,CACER,KAAM,gBACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,kBACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,qBACNC,KAAM,yBACNG,MAAO,OACPjB,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,SAKZU,OAAQ,CACN,CACET,KAAM,mBACNC,KAAM,yBACNG,MAAO,OACPjB,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,UACNC,KAAM,yBACNG,MAAO,OACPjB,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,UACNC,KAAM,yBACNG,MAAO,OACPjB,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,sBACNC,KAAM,yBACNG,MAAO,OACPjB,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,oBACNC,KAAM,yBACNG,MAAO,OACPjB,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,QACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,SACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,oBACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,qBACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,aACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,eACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,gBACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,qBACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,sBACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,eACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,oBACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,SACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,SAMZW,OAAQ,CACN,CACEV,KAAM,mBACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,cACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,gBACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,aACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,QAIV,CACEC,KAAM,gBACNI,MAAO,OACPH,KAAM,yBACNd,KAAM,CACJ,CACEW,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,MAEN,CACED,GAAI,KACJC,GAAI,SAMhB,GC59B0I,ICQxI,GAAY,OACd,EACA,EACA,GACA,EACA,KACA,WACA,MAIF,EAAe,EAAiB,QCnB5B,EAAS,WAAkB,IAAIzB,EAAIC,KAAQD,EAAIG,MAAMD,GAAG,OAAOF,EAAIU,GAAG,EAC1E,EACI,EAAkB,CAAC,WAAY,IAAIV,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,MAAM,CAACM,YAAY,sBAAsB,CAACN,EAAG,MAAM,CAACM,YAAY,yDAAyD,CAACN,EAAG,MAAM,CAACM,YAAY,oCAAoC,CAACR,EAAIW,GAAG,8DAA8DT,EAAG,MAAM,CAACM,YAAY,wCAAwC,CAACN,EAAG,MAAM,CAACF,EAAIW,GAAG,6zBAA6zBT,EAAG,MAAM,CAACM,YAAY,aAAaJ,MAAM,CAAC,IAAM,oDAAoD,IAAM,MAAMF,EAAG,MAAM,CAACM,YAAY,aAAaJ,MAAM,CAAC,IAAM,sCAAsC,IAAM,MAAMF,EAAG,MAAM,CAACM,YAAY,SAAS,CAACR,EAAIW,GAAG,sVAAsVT,EAAG,MAAM,CAACM,YAAY,yDAAyD,CAACN,EAAG,MAAM,CAACM,YAAY,oCAAoC,CAACR,EAAIW,GAAG,oBAAoBT,EAAG,MAAM,CAACM,YAAY,2BAA2B,CAACN,EAAG,MAAM,CAACM,YAAY,aAAaJ,MAAM,CAAC,IAAM,0CAA0C,IAAM,MAAMF,EAAG,MAAM,CAACM,YAAY,aAAaJ,MAAM,CAAC,IAAM,2CAA2C,IAAM,MAAMF,EAAG,MAAM,CAACM,YAAY,SAAS,CAACR,EAAIW,GAAG,uVAC5uE,GCoEA,GAAiB,ECvEqH,ICQlI,GAAY,OACd,EACA,EACA,GACA,EACA,KACA,WACA,MAIF,EAAe,EAAiB,QCnB5B,EAAS,WAAkB,IAAIX,EAAIC,KAAQD,EAAIG,MAAMD,GAAG,OAAOF,EAAIU,GAAG,EAC1E,EACI,EAAkB,CAAC,WAAY,IAAIV,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,MAAM,CAACM,YAAY,oEAAoEI,YAAY,CAAC,mBAAmB,YAAY,CAACV,EAAG,IAAI,CAACF,EAAIW,GAAG,0CAA0CT,EAAG,IAAI,CAACE,MAAM,CAAC,KAAO,+BAA+B,CAACJ,EAAIW,GAAG,aAAaX,EAAIW,GAAG,SAAST,EAAG,IAAI,CAACE,MAAM,CAAC,KAAO,iCAAiC,CAACJ,EAAIW,GAAG,eAAeX,EAAIW,GAAG,uBAAuBT,EAAG,IAAI,CAACE,MAAM,CAAC,IAAM,UAAU,KAAO,mDAAmD,CAACJ,EAAIW,GAAG,uEAAuEX,EAAIW,GAAG,SAC5nB,GCcA,GAAiB,ECjBsH,ICOnI,GAAY,OACd,EACA,EACA,GACA,EACA,KACA,KACA,MAIF,EAAe,EAAiB,QCiBhC,GACE0B,KAAM,WACNC,WAAY,CACVC,QAAO,EACPC,SAAQ,EACRC,gBAAe,EACfC,UAAS,EACTC,WAAU,GAEZ,IAAA9B,GACE,MAAO,CAAC,CACV,EACA,OAAA+B,GAAW,EACXC,QAAS,CAuBT,GCvEmI,ICQjI,GAAY,OACd,EACA,EACA,GACA,EACA,KACA,KACA,MAIF,EAAe,EAAiB,QCfhC,aAAIC,IAAI,MAER,MAAMC,EAAS,CACb,CACEC,KAAM,IACNX,KAAM,OACN9B,UAAW0C,IAITC,EAAS,IAAI,KAAU,CAC3BC,KAAM,OACNC,KAAM,GACNL,WAGF,QCbA,aAAID,IAAI,KACR,aAAIO,OAAOC,eAAgB,EAE3B,IAAI,aAAI,CACNJ,OAAM,EACNnD,OAAQ,SAAUwD,GAChB,OAAOA,EAAEC,EACX,IACCC,OAAO,O,GCdNC,EAA2B,CAAC,EAGhC,SAASC,EAAoBC,GAE5B,IAAIC,EAAeH,EAAyBE,GAC5C,QAAqBE,IAAjBD,EACH,OAAOA,EAAaE,QAGrB,IAAIC,EAASN,EAAyBE,GAAY,CACjD3C,GAAI2C,EACJK,QAAQ,EACRF,QAAS,CAAC,GAUX,OANAG,EAAoBN,GAAUI,EAAQA,EAAOD,QAASJ,GAGtDK,EAAOC,QAAS,EAGTD,EAAOD,OACf,CAGAJ,EAAoBQ,EAAID,E,WC5BxBP,EAAoBS,KAAO,CAAC,C,eCA5B,IAAIC,EAAW,GACfV,EAAoBW,EAAI,SAASC,EAAQC,EAAUC,EAAIC,GACtD,IAAGF,EAAH,CAMA,IAAIG,EAAeC,IACnB,IAASC,EAAI,EAAGA,EAAIR,EAASS,OAAQD,IAAK,CACrCL,EAAWH,EAASQ,GAAG,GACvBJ,EAAKJ,EAASQ,GAAG,GACjBH,EAAWL,EAASQ,GAAG,GAE3B,IAJA,IAGIE,GAAY,EACPC,EAAI,EAAGA,EAAIR,EAASM,OAAQE,MACpB,EAAXN,GAAsBC,GAAgBD,IAAaO,OAAOC,KAAKvB,EAAoBW,GAAGa,OAAM,SAAS9D,GAAO,OAAOsC,EAAoBW,EAAEjD,GAAKmD,EAASQ,GAAK,IAChKR,EAASY,OAAOJ,IAAK,IAErBD,GAAY,EACTL,EAAWC,IAAcA,EAAeD,IAG7C,GAAGK,EAAW,CACbV,EAASe,OAAOP,IAAK,GACrB,IAAIQ,EAAIZ,SACEX,IAANuB,IAAiBd,EAASc,EAC/B,CACD,CACA,OAAOd,CArBP,CAJCG,EAAWA,GAAY,EACvB,IAAI,IAAIG,EAAIR,EAASS,OAAQD,EAAI,GAAKR,EAASQ,EAAI,GAAG,GAAKH,EAAUG,IAAKR,EAASQ,GAAKR,EAASQ,EAAI,GACrGR,EAASQ,GAAK,CAACL,EAAUC,EAAIC,EAwB/B,C,eC5BAf,EAAoB2B,EAAI,SAAStB,GAChC,IAAIuB,EAASvB,GAAUA,EAAOwB,WAC7B,WAAa,OAAOxB,EAAO,UAAY,EACvC,WAAa,OAAOA,CAAQ,EAE7B,OADAL,EAAoB8B,EAAEF,EAAQ,CAAE1D,EAAG0D,IAC5BA,CACR,C,eCNA5B,EAAoB8B,EAAI,SAAS1B,EAAS2B,GACzC,IAAI,IAAIrE,KAAOqE,EACX/B,EAAoBgC,EAAED,EAAYrE,KAASsC,EAAoBgC,EAAE5B,EAAS1C,IAC5E4D,OAAOW,eAAe7B,EAAS1C,EAAK,CAAEwE,YAAY,EAAMC,IAAKJ,EAAWrE,IAG3E,C,eCPAsC,EAAoBoC,EAAI,WACvB,GAA0B,kBAAfC,WAAyB,OAAOA,WAC3C,IACC,OAAO/F,MAAQ,IAAIgG,SAAS,cAAb,EAChB,CAAE,MAAOC,GACR,GAAsB,kBAAXC,OAAqB,OAAOA,MACxC,CACA,CAPuB,E,eCAxBxC,EAAoBgC,EAAI,SAASS,EAAK1E,GAAQ,OAAOuD,OAAOoB,UAAUC,eAAeC,KAAKH,EAAK1E,EAAO,C,eCCtGiC,EAAoB0B,EAAI,SAAStB,GACX,qBAAXyC,QAA0BA,OAAOC,aAC1CxB,OAAOW,eAAe7B,EAASyC,OAAOC,YAAa,CAAEC,MAAO,WAE7DzB,OAAOW,eAAe7B,EAAS,aAAc,CAAE2C,OAAO,GACvD,C,eCNA/C,EAAoBgD,IAAM,SAAS3C,GAGlC,OAFAA,EAAO4C,MAAQ,GACV5C,EAAO6C,WAAU7C,EAAO6C,SAAW,IACjC7C,CACR,C,eCCA,IAAI8C,EAAkB,CACrB,IAAK,GAaNnD,EAAoBW,EAAEU,EAAI,SAAS+B,GAAW,OAAoC,IAA7BD,EAAgBC,EAAgB,EAGrF,IAAIC,EAAuB,SAASC,EAA4BpG,GAC/D,IAKI+C,EAAUmD,EALVvC,EAAW3D,EAAK,GAChBqG,EAAcrG,EAAK,GACnBsG,EAAUtG,EAAK,GAGIgE,EAAI,EAC3B,GAAGL,EAAS4C,MAAK,SAASnG,GAAM,OAA+B,IAAxB6F,EAAgB7F,EAAW,IAAI,CACrE,IAAI2C,KAAYsD,EACZvD,EAAoBgC,EAAEuB,EAAatD,KACrCD,EAAoBQ,EAAEP,GAAYsD,EAAYtD,IAGhD,GAAGuD,EAAS,IAAI5C,EAAS4C,EAAQxD,EAClC,CAEA,IADGsD,GAA4BA,EAA2BpG,GACrDgE,EAAIL,EAASM,OAAQD,IACzBkC,EAAUvC,EAASK,GAChBlB,EAAoBgC,EAAEmB,EAAiBC,IAAYD,EAAgBC,IACrED,EAAgBC,GAAS,KAE1BD,EAAgBC,GAAW,EAE5B,OAAOpD,EAAoBW,EAAEC,EAC9B,EAEI8C,EAAqBC,KAAK,yBAA2BA,KAAK,0BAA4B,GAC1FD,EAAmBE,QAAQP,EAAqBQ,KAAK,KAAM,IAC3DH,EAAmBI,KAAOT,EAAqBQ,KAAK,KAAMH,EAAmBI,KAAKD,KAAKH,G,IC/CvF,IAAIK,EAAsB/D,EAAoBW,OAAER,EAAW,CAAC,MAAM,WAAa,OAAOH,EAAoB,KAAO,IACjH+D,EAAsB/D,EAAoBW,EAAEoD,E","sources":["webpack://portfolio/./src/App.vue?9902","webpack://portfolio/./src/App.vue","webpack://portfolio/./src/views/HomeView.vue?2e32","webpack://portfolio/./src/components/TopMenu.vue?8e4e","webpack://portfolio/src/components/TopMenu.vue","webpack://portfolio/./src/components/TopMenu.vue?fc0f","webpack://portfolio/./src/components/TopMenu.vue","webpack://portfolio/./src/components/HomePage.vue?1925","webpack://portfolio/src/components/HomePage.vue","webpack://portfolio/./src/components/HomePage.vue?3cdb","webpack://portfolio/./src/components/HomePage.vue","webpack://portfolio/./src/components/ExperimentsPage.vue?96ef","webpack://portfolio/src/components/ExperimentsPage.vue","webpack://portfolio/./src/components/ExperimentsPage.vue?7dbf","webpack://portfolio/./src/components/ExperimentsPage.vue","webpack://portfolio/./src/components/ThirdPart.vue?75c3","webpack://portfolio/src/components/ThirdPart.vue","webpack://portfolio/./src/components/ThirdPart.vue?a0ad","webpack://portfolio/./src/components/ThirdPart.vue","webpack://portfolio/./src/components/FooterPart.vue?2a6b","webpack://portfolio/src/components/FooterPart.vue","webpack://portfolio/./src/components/FooterPart.vue?82a2","webpack://portfolio/./src/components/FooterPart.vue","webpack://portfolio/src/views/HomeView.vue","webpack://portfolio/./src/views/HomeView.vue?3bee","webpack://portfolio/./src/views/HomeView.vue","webpack://portfolio/./src/router/index.js","webpack://portfolio/./src/main.js","webpack://portfolio/webpack/bootstrap","webpack://portfolio/webpack/runtime/amd options","webpack://portfolio/webpack/runtime/chunk loaded","webpack://portfolio/webpack/runtime/compat get default export","webpack://portfolio/webpack/runtime/define property getters","webpack://portfolio/webpack/runtime/global","webpack://portfolio/webpack/runtime/hasOwnProperty shorthand","webpack://portfolio/webpack/runtime/make namespace object","webpack://portfolio/webpack/runtime/node module decorator","webpack://portfolio/webpack/runtime/jsonp chunk loading","webpack://portfolio/webpack/startup"],"sourcesContent":["var render = function render(){var _vm=this,_c=_vm._self._c;return _c('div',{attrs:{\"id\":\"app\"}},[_c('router-view')],1)\n}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","import { render, staticRenderFns } from \"./App.vue?vue&type=template&id=03b46458&\"\nvar script = {}\n\n\n/* normalize component */\nimport normalizer from \"!../node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports","var render = function render(){var _vm=this,_c=_vm._self._c;return _c('div',{staticClass:\"HomePage h-full w-full text-lg\"},[_c('TopMenu',{ref:\"TopMenu\"}),_c('HomePage'),_c('ExperimentsPage'),_c('ThirdPart'),_c('FooterPart')],1)\n}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","var render = function render(){var _vm=this,_c=_vm._self._c;return _vm._m(0)\n}\nvar staticRenderFns = [function (){var _vm=this,_c=_vm._self._c;return _c('div',{staticClass:\"TopMenu h-full text-center flex justify-center items-center pt-40 flex-col\"},[_c('div',{staticClass:\"Title\"},[_vm._v(\" PathMMU: A Massive Multimodal Expert-Level Benchmark \"),_c('br'),_c('div',{staticClass:\"pt-2\"}),_vm._v(\" for Understanding and Reasoning in Pathology \")]),_c('div',{staticClass:\"pt-5\"},[_vm._v(\" A large-scale, high-quality, comprehensive and specialized database for pathology \")]),_c('div',{staticClass:\"author pt-5\"},[_vm._v(\" Yuxuan Sun,Hao Wu,Chenglu Zhu, \"),_c('br'),_vm._v(\" Sunyi Zheng,Qizi Chen,Kai Zhang,Yunlong Zhang,XXXX,Mengyue Zheng, \"),_c('br'),_vm._v(\" Jingxiong Li, Xinheng Lyu, Tao Lin,Lin Yang \")]),_c('div',{staticClass:\"author pt-10\"},[_vm._v(\" Westlake University, Macau University of Science and Technology, Jiangnan University,\"),_c('br'),_vm._v(\" The Ohio State University, Zhejiang University, \")]),_c('div',{staticClass:\"pt-5\"},[_c('div',[_vm._v(\"*Core Contributors\")]),_c('div',[_vm._v(\" †Corresponding to: \"),_c('a',{staticClass:\"text-blue-400\",attrs:{\"href\":\"\"}},[_vm._v(\"xiangyue.work@gmail.com\")]),_vm._v(\", \"),_c('a',{staticClass:\"text-blue-400\",attrs:{\"href\":\"\"}},[_vm._v(\"su.809@osu.edu, wenhuchen@uwaterloo.ca\")])])]),_c('div',{staticClass:\"btn_list pt-5 flex items-center text-base pb-8\"},[_c('div',{staticClass:\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\",staticStyle:{\"background\":\"#363636\"}},[_vm._v(\" arXiv \")]),_c('div',{staticClass:\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\",staticStyle:{\"background\":\"#363636\"}},[_vm._v(\" HF Paper \")]),_c('div',{staticClass:\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\",staticStyle:{\"background\":\"#363636\"}},[_vm._v(\" Dataset \")]),_c('div',{staticClass:\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\",staticStyle:{\"background\":\"#363636\"}},[_vm._v(\" Code \")]),_c('div',{staticClass:\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\",staticStyle:{\"background\":\"#363636\"}},[_vm._v(\" Leaderboard \")]),_c('div',{staticClass:\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\",staticStyle:{\"background\":\"#363636\"}},[_vm._v(\" EvalAI \")]),_c('div',{staticClass:\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\",staticStyle:{\"background\":\"#363636\"}},[_vm._v(\" Twitter \")]),_c('div',{staticClass:\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\",staticStyle:{\"background\":\"#363636\"}},[_vm._v(\" Examples \")])]),_c('div',{staticClass:\"overall w-7/12 pt-5\"},[_c('img',{attrs:{\"src\":\"resources/img/figures/overall.png\",\"alt\":\"\"}}),_c('div',{staticClass:\"pt-10 pb-3 text-justify\"},[_vm._v(\" The emergence of large multimodal models has unlocked remarkable potential in AI, particularly in pathology. However, the lack of specialized, high-quality benchmark impeded their development and precise evaluation. To address this, we introduce PathMMU, the largest and highest-quality expert-validated pathology benchmark for LMMs. It comprises 33,573 multimodal multi-choice questions and 21,599 images from various sources, and an explanation for the correct answer accompanies each question. The construction of PathMMU capitalizes on the robust capabilities of GPT-4V, utilizing approximately 30,000 gathered image-caption pairs to generate Q&As. Significantly, to maximize PathMMU's authority, we invite six pathologists to scrutinize each question under strict standards in PathMMU's validation and test sets, while simultaneously setting an expert-level performance benchmark for PathMMU. We conduct extensive evaluations, including zero-shot assessments of 14 open-sourced and 3 closed-sourced LMMs and their robustness to image corruption. We also fine-tune representative LMMs to assess their adaptability to PathMMU. The empirical findings indicate that advanced LMMs struggle with the challenging PathMMU benchmark, with the top-performing LMM, GPT-4V, achieving only a 51.7% zero-shot performance, significantly lower than the 71.4% demonstrated by human pathologists. After fine-tuning, even open-sourced LMMs can surpass GPT-4V with a performance of over 60%, but still fall short of the expertise shown by pathologists. \")])]),_c('div',{staticClass:\"Intro pt-10 w-7/12\"},[_c('div',{staticClass:\"head font-bold pb-5\"},[_vm._v(\"Introduction\")]),_c('div',{staticClass:\"content text-justify pb-10\"},[_vm._v(\" The Pathology Multimodal Multitask Unsupervised Benchmark (MMMU) dataset is a large-scale, multimodal, multitask dataset for understanding and reasoning in pathology. The dataset is designed to be comprehensive, diverse, and challenging, and is intended to serve as a benchmark for research in multimodal pathology understanding and reasoning. \")])])])\n}]\n\nexport { render, staticRenderFns }","<template>\n  <div\n    class=\"TopMenu h-full text-center flex justify-center items-center pt-40 flex-col\"\n  >\n    <div class=\"Title\">\n      PathMMU: A Massive Multimodal Expert-Level Benchmark <br />\n      <div class=\"pt-2\"></div>\n      for Understanding and Reasoning in Pathology\n    </div>\n    <div class=\"pt-5\">\n      A large-scale, high-quality, comprehensive and specialized database for\n      pathology\n    </div>\n    <div class=\"author pt-5\">\n      Yuxuan Sun,Hao Wu,Chenglu Zhu,\n      <br />\n      Sunyi Zheng,Qizi Chen,Kai Zhang,Yunlong Zhang,XXXX,Mengyue Zheng,\n      <br />\n      Jingxiong Li, Xinheng Lyu, Tao Lin,Lin Yang\n    </div>\n    <div class=\"author pt-10\">\n      Westlake University, Macau University of Science and Technology, Jiangnan\n      University,<br />\n      The Ohio State University, Zhejiang University,\n    </div>\n    <div class=\"pt-5\">\n      <div>*Core Contributors</div>\n      <div>\n        †Corresponding to:\n        <a href=\"\" class=\"text-blue-400\">xiangyue.work@gmail.com</a>,\n        <a href=\"\" class=\"text-blue-400\"\n          >su.809@osu.edu, wenhuchen@uwaterloo.ca</a\n        >\n      </div>\n    </div>\n    <div class=\"btn_list pt-5 flex items-center text-base pb-8\">\n      <div\n        class=\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\"\n        style=\"background: #363636\"\n      >\n        arXiv\n      </div>\n      <div\n        class=\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\"\n        style=\"background: #363636\"\n      >\n        HF Paper\n      </div>\n      <div\n        class=\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\"\n        style=\"background: #363636\"\n      >\n        Dataset\n      </div>\n      <div\n        class=\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\"\n        style=\"background: #363636\"\n      >\n        Code\n      </div>\n      <div\n        class=\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\"\n        style=\"background: #363636\"\n      >\n        Leaderboard\n      </div>\n      <div\n        class=\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\"\n        style=\"background: #363636\"\n      >\n        EvalAI\n      </div>\n      <div\n        class=\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\"\n        style=\"background: #363636\"\n      >\n        Twitter\n      </div>\n      <div\n        class=\"rounded-3xl text-white pl-3 pr-3 pt-2 pb-2\"\n        style=\"background: #363636\"\n      >\n        Examples\n      </div>\n    </div>\n    <div class=\"overall w-7/12 pt-5\">\n      <img src=\"resources/img/figures/overall.png\" alt=\"\" />\n      <div class=\"pt-10 pb-3 text-justify\">\n        The emergence of large multimodal models has unlocked remarkable\n        potential in AI, particularly in pathology. However, the lack of\n        specialized, high-quality benchmark impeded their development and\n        precise evaluation. To address this, we introduce PathMMU, the largest\n        and highest-quality expert-validated pathology benchmark for LMMs. It\n        comprises 33,573 multimodal multi-choice questions and 21,599 images\n        from various sources, and an explanation for the correct answer\n        accompanies each question. The construction of PathMMU capitalizes on\n        the robust capabilities of GPT-4V, utilizing approximately 30,000\n        gathered image-caption pairs to generate Q&As. Significantly, to\n        maximize PathMMU's authority, we invite six pathologists to scrutinize\n        each question under strict standards in PathMMU's validation and test\n        sets, while simultaneously setting an expert-level performance benchmark\n        for PathMMU. We conduct extensive evaluations, including zero-shot\n        assessments of 14 open-sourced and 3 closed-sourced LMMs and their\n        robustness to image corruption. We also fine-tune representative LMMs to\n        assess their adaptability to PathMMU. The empirical findings indicate\n        that advanced LMMs struggle with the challenging PathMMU benchmark, with\n        the top-performing LMM, GPT-4V, achieving only a 51.7% zero-shot\n        performance, significantly lower than the 71.4% demonstrated by human\n        pathologists. After fine-tuning, even open-sourced LMMs can surpass\n        GPT-4V with a performance of over 60%, but still fall short of the\n        expertise shown by pathologists.\n      </div>\n    </div>\n    <div class=\"Intro pt-10 w-7/12\">\n      <div class=\"head font-bold pb-5\">Introduction</div>\n      <div class=\"content text-justify pb-10\">\n        The Pathology Multimodal Multitask Unsupervised Benchmark (MMMU) dataset\n        is a large-scale, multimodal, multitask dataset for understanding and\n        reasoning in pathology. The dataset is designed to be comprehensive,\n        diverse, and challenging, and is intended to serve as a benchmark for\n        research in multimodal pathology understanding and reasoning.\n      </div>\n    </div>\n  </div>\n</template>\n\n<script>\nexport default {\n  data() {\n    return {\n      publicUrl: \"./public/\",\n      topMenu: [\n        { content: \"HOME\", id: 0 },\n        // { content: \"PHOTOGRAPHY\", id: 1 },\n        { content: \"ABOUT\", id: 2 },\n        { content: \"CONCACT\", id: 3 },\n      ],\n    };\n  },\n};\n</script>\n\n<style scoped>\n.Title {\n  color: #4a4a4a;\n  font-size: 2rem;\n}\n.Intro .head {\n  font-size: 2rem;\n}\n</style>\n","import mod from \"-!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./TopMenu.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./TopMenu.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./TopMenu.vue?vue&type=template&id=256e8e8f&scoped=true&\"\nimport script from \"./TopMenu.vue?vue&type=script&lang=js&\"\nexport * from \"./TopMenu.vue?vue&type=script&lang=js&\"\nimport style0 from \"./TopMenu.vue?vue&type=style&index=0&id=256e8e8f&prod&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"256e8e8f\",\n  null\n  \n)\n\nexport default component.exports","var render = function render(){var _vm=this,_c=_vm._self._c;return _vm._m(0)\n}\nvar staticRenderFns = [function (){var _vm=this,_c=_vm._self._c;return _c('div',{staticClass:\"HomePage w-full h-full\"},[_c('div',{staticClass:\"bg w-full h-20 flex justify-center items-center font-bold text-4xl\"},[_vm._v(\" PATHMMU BENCHMARK \")]),_c('div',{staticClass:\"PageContent flex justify-center items-center flex-col\"},[_c('div',{staticClass:\"headtitle text-3xl font-bold p-5\"},[_vm._v(\"Overview\")]),_c('div',{staticClass:\"overview_content w-7/12\"},[_c('div',{staticClass:\"text-justify\"},[_vm._v(\" We introduce the Massive Multi-discipline Multimodal Understanding and Reasoning (MMMU) benchmark, a novel benchmark meticulously curated to assess the expert-level multimodal understanding capability of foundation models across a broad scope of tasks. Covering subjects across disciplines, including Art, Business, Health & Medicine, Science, Humanities & Social Science, and Tech & Engineering, and over subfields. The detailed subject coverage and statistics are detailed in the figure. The questions in our benchmark were manually collected by a team of college students (including coauthors) from various disciplines and subjects, drawing from online sources, textbooks, and lecture materials. \")]),_c('img',{staticClass:\"pt-10 pb-10\",attrs:{\"src\":\"resources/img/figures/overall.png\",\"alt\":\"\"}}),_c('div')])]),_c('div',{staticClass:\"w-7/12 pt-10 pb-5\",staticStyle:{\"margin\":\"0 auto\"}},[_c('div',{staticClass:\"FeatureTitle\"},[_vm._v(\"Key Features\")]),_c('div',{staticClass:\"FeatureContent grid grid-cols-3 gap-3\"},[_c('div',[_c('div',{staticClass:\"SubTitle\"},[_vm._v(\"Large-Scale\")]),_c('div',{staticClass:\"subContent text-left\"},[_vm._v(\" The dataset contains more than 10,000 video segments of real-world moving objects and over 1.5 million manually labeled bounding boxes \")])]),_c('div',[_c('div',{staticClass:\"SubTitle\"},[_vm._v(\"Large-Scale\")]),_c('div',{staticClass:\"subContent text-left\"},[_vm._v(\" The dataset contains more than 10,000 video segments of real-world moving objects and over 1.5 million manually labeled bounding boxes \")])]),_c('div',[_c('div',{staticClass:\"SubTitle\"},[_vm._v(\"Large-Scale\")]),_c('div',{staticClass:\"subContent text-left\"},[_vm._v(\" The dataset contains more than 10,000 video segments of real-world moving objects and over 1.5 million manually labeled bounding boxes \")])]),_c('div',[_c('div',{staticClass:\"SubTitle\"},[_vm._v(\"Large-Scale\")]),_c('div',{staticClass:\"subContent text-left\"},[_vm._v(\" The dataset contains more than 10,000 video segments of real-world moving objects and over 1.5 million manually labeled bounding boxes \")])]),_c('div',[_c('div',{staticClass:\"SubTitle\"},[_vm._v(\"Large-Scale\")]),_c('div',{staticClass:\"subContent text-left\"},[_vm._v(\" The dataset contains more than 10,000 video segments of real-world moving objects and over 1.5 million manually labeled bounding boxes \")])]),_c('div',[_c('div',{staticClass:\"SubTitle\"},[_vm._v(\"Large-Scale\")]),_c('div',{staticClass:\"subContent text-left\"},[_vm._v(\" The dataset contains more than 10,000 video segments of real-world moving objects and over 1.5 million manually labeled bounding boxes \")])])])]),_c('div',{staticClass:\"w-7/12 pt-10 pb-5\",staticStyle:{\"margin\":\"0 auto\"}},[_c('div',{staticClass:\"font-bold text-red-500 text-2xl pb-3\"},[_vm._v(\"Latest News\")]),_c('ul',[_c('li',[_vm._v(\" [2023.09.12] The SOTVerse paper has been accepted by International Journal of Computer Vision (IJCV)! \")]),_c('li',[_vm._v(\" [2022.04.18] We have released SOTVerse, a user-defined task space of single object tracking, and the related paper has been released on arXiv. \")]),_c('li',[_vm._v(\" [2022.03.29] The IEEE TPAMI paper is selected as \\\"ESI Hot Papers\\\"! \")]),_c('li',[_vm._v(\" [2021.09.14] The IEEE TPAMI paper is selected as \\\"ESI Highly Cited Papers\\\"! \")])])]),_c('div',{staticClass:\"w-7/12 pt-10 pb-5\",staticStyle:{\"margin\":\"0 auto\"}},[_c('div',{staticClass:\"text-2xl pb-3\"},[_vm._v(\"Publications\")]),_c('div',{staticClass:\"flex items-center\"},[_c('img',{attrs:{\"src\":\"resources/img/figures/publication.png\",\"alt\":\"\"}}),_c('div',{staticClass:\"pl-5\"},[_c('div',{staticClass:\"intro\"},[_vm._v(\" GOT-10k: A Large High-Diversity Benchmark for Generic Object Tracking in the Wild. L. Huang*, X. Zhao*, and K. Huang. ( *Equal contribution) IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). \")]),_c('div',{staticClass:\"link\"},[_c('a',{staticClass:\"text-blue-600\",attrs:{\"href\":\"\"}},[_vm._v(\"[PDF] \")]),_c('a',{staticClass:\"text-blue-600\",attrs:{\"href\":\"\"}},[_vm._v(\"[ArXiv]\")]),_c('a',{staticClass:\"text-blue-600\",attrs:{\"href\":\"\"}},[_vm._v(\"[BibTex]\")])])])]),_c('div',{staticClass:\"text-gray-500 pt-5\"},[_c('i',[_vm._v(\"Please cite this paper if GOT-10k helps your research.\")])])]),_c('div',{staticClass:\"PageContent flex justify-center items-center flex-col\"},[_c('div',{staticClass:\"headtitle text-3xl font-bold p-5\"},[_vm._v(\" Comparisons with Existing Benchmarks \")]),_c('div',{staticClass:\"overview_content w-7/12\"},[_c('div',{staticClass:\"text-justify\"},[_vm._v(\" We introduce the Massive Multi-discipline Multimodal Understanding and Reasoning (MMMU) benchmark, a novel benchmark meticulously curated to assess the expert-level multimodal understanding capability of foundation models across a broad scope of tasks. Covering subjects across disciplines, including Art, Business, Health & Medicine, Science, Humanities & Social Science, and Tech & Engineering, and over subfields. The detailed subject coverage and statistics are detailed in the figure. The questions in our benchmark were manually collected by a team of college students (including coauthors) from various disciplines and subjects, drawing from online sources, textbooks, and lecture materials. \")]),_c('img',{staticClass:\"pt-10 pb-2\",attrs:{\"src\":\"resources/img/figures/data_comparison.png\",\"alt\":\"\"}}),_c('div',{staticClass:\"pb-10 pt-5\"},[_vm._v(\" Sampled MMMU examples from each discipline. The questions and images need expert-level knowledge to understand and reason. \")])])])])\n}]\n\nexport { render, staticRenderFns }","<template>\n  <div class=\"HomePage w-full h-full\">\n    <div\n      class=\"bg w-full h-20 flex justify-center items-center font-bold text-4xl\"\n    >\n      PATHMMU BENCHMARK\n    </div>\n    <div class=\"PageContent flex justify-center items-center flex-col\">\n      <!-- overview -->\n      <div class=\"headtitle text-3xl font-bold p-5\">Overview</div>\n      <div class=\"overview_content w-7/12\">\n        <div class=\"text-justify\">\n          We introduce the Massive Multi-discipline Multimodal Understanding and\n          Reasoning (MMMU) benchmark, a novel benchmark meticulously curated to\n          assess the expert-level multimodal understanding capability of\n          foundation models across a broad scope of tasks. Covering subjects\n          across disciplines, including Art, Business, Health & Medicine,\n          Science, Humanities & Social Science, and Tech & Engineering, and over\n          subfields. The detailed subject coverage and statistics are detailed\n          in the figure. The questions in our benchmark were manually collected\n          by a team of college students (including coauthors) from various\n          disciplines and subjects, drawing from online sources, textbooks, and\n          lecture materials.\n        </div>\n        <img\n          src=\"resources/img/figures/overall.png\"\n          class=\"pt-10 pb-10\"\n          alt=\"\"\n        />\n        <div></div>\n      </div>\n    </div>\n    <!-- Feature -->\n    <div class=\"w-7/12 pt-10 pb-5\" style=\"margin: 0 auto\">\n      <div class=\"FeatureTitle\">Key Features</div>\n      <div class=\"FeatureContent grid grid-cols-3 gap-3\">\n        <div>\n          <div class=\"SubTitle\">Large-Scale</div>\n          <div class=\"subContent text-left\">\n            The dataset contains more than 10,000 video segments of real-world\n            moving objects and over 1.5 million manually labeled bounding boxes\n          </div>\n        </div>\n        <div>\n          <div class=\"SubTitle\">Large-Scale</div>\n          <div class=\"subContent text-left\">\n            The dataset contains more than 10,000 video segments of real-world\n            moving objects and over 1.5 million manually labeled bounding boxes\n          </div>\n        </div>\n        <div>\n          <div class=\"SubTitle\">Large-Scale</div>\n          <div class=\"subContent text-left\">\n            The dataset contains more than 10,000 video segments of real-world\n            moving objects and over 1.5 million manually labeled bounding boxes\n          </div>\n        </div>\n        <div>\n          <div class=\"SubTitle\">Large-Scale</div>\n          <div class=\"subContent text-left\">\n            The dataset contains more than 10,000 video segments of real-world\n            moving objects and over 1.5 million manually labeled bounding boxes\n          </div>\n        </div>\n        <div>\n          <div class=\"SubTitle\">Large-Scale</div>\n          <div class=\"subContent text-left\">\n            The dataset contains more than 10,000 video segments of real-world\n            moving objects and over 1.5 million manually labeled bounding boxes\n          </div>\n        </div>\n        <div>\n          <div class=\"SubTitle\">Large-Scale</div>\n          <div class=\"subContent text-left\">\n            The dataset contains more than 10,000 video segments of real-world\n            moving objects and over 1.5 million manually labeled bounding boxes\n          </div>\n        </div>\n      </div>\n    </div>\n    <!-- Latest news -->\n    <div class=\"w-7/12 pt-10 pb-5\" style=\"margin: 0 auto\">\n      <div class=\"font-bold text-red-500 text-2xl pb-3\">Latest News</div>\n      <ul>\n        <li>\n          [2023.09.12] The SOTVerse paper has been accepted by International\n          Journal of Computer Vision (IJCV)!\n        </li>\n        <li>\n          [2022.04.18] We have released SOTVerse, a user-defined task space of\n          single object tracking, and the related paper has been released on\n          arXiv.\n        </li>\n        <li>\n          [2022.03.29] The IEEE TPAMI paper is selected as \"ESI Hot Papers\"!\n        </li>\n        <li>\n          [2021.09.14] The IEEE TPAMI paper is selected as \"ESI Highly Cited\n          Papers\"!\n        </li>\n      </ul>\n    </div>\n    <!-- publication -->\n    <div class=\"w-7/12 pt-10 pb-5\" style=\"margin: 0 auto\">\n      <div class=\"text-2xl pb-3\">Publications</div>\n      <div class=\"flex items-center\">\n        <img src=\"resources/img/figures/publication.png\" alt=\"\" />\n        <div class=\"pl-5\">\n          <div class=\"intro\">\n            GOT-10k: A Large High-Diversity Benchmark for Generic Object\n            Tracking in the Wild. L. Huang*, X. Zhao*, and K. Huang. ( *Equal\n            contribution) IEEE Transactions on Pattern Analysis and Machine\n            Intelligence (TPAMI).\n          </div>\n          <div class=\"link\">\n            <a href=\"\" class=\"text-blue-600\">[PDF] </a>\n            <a href=\"\" class=\"text-blue-600\">[ArXiv]</a>\n            <a href=\"\" class=\"text-blue-600\">[BibTex]</a>\n          </div>\n        </div>\n      </div>\n      <div class=\"text-gray-500 pt-5\">\n        <i>Please cite this paper if GOT-10k helps your research.</i>\n      </div>\n    </div>\n    <!-- Comparisons  -->\n    <div class=\"PageContent flex justify-center items-center flex-col\">\n      <!-- overview -->\n      <div class=\"headtitle text-3xl font-bold p-5\">\n        Comparisons with Existing Benchmarks\n      </div>\n      <div class=\"overview_content w-7/12\">\n        <div class=\"text-justify\">\n          We introduce the Massive Multi-discipline Multimodal Understanding and\n          Reasoning (MMMU) benchmark, a novel benchmark meticulously curated to\n          assess the expert-level multimodal understanding capability of\n          foundation models across a broad scope of tasks. Covering subjects\n          across disciplines, including Art, Business, Health & Medicine,\n          Science, Humanities & Social Science, and Tech & Engineering, and over\n          subfields. The detailed subject coverage and statistics are detailed\n          in the figure. The questions in our benchmark were manually collected\n          by a team of college students (including coauthors) from various\n          disciplines and subjects, drawing from online sources, textbooks, and\n          lecture materials.\n        </div>\n        <img\n          src=\"resources/img/figures/data_comparison.png\"\n          class=\"pt-10 pb-2\"\n          alt=\"\"\n        />\n        <div class=\"pb-10 pt-5\">\n          Sampled MMMU examples from each discipline. The questions and images\n          need expert-level knowledge to understand and reason.\n        </div>\n      </div>\n    </div>\n  </div>\n</template>\n\n<script>\nexport default {};\n</script>\n\n<style scoped>\n.bg {\n  background-color: #f5f5f5;\n  color: rgba(0, 0, 0, 0.7);\n}\n.FeatureTitle {\n  color: #6f6e6e;\n  font-size: 27px;\n}\n.SubTitle {\n  color: #6f6e6e;\n  margin-top: 20px;\n  font-size: 20px;\n}\n.subContent {\n  font-size: 16px;\n  color: #6f6e6e;\n}\n</style>\n","import mod from \"-!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./HomePage.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./HomePage.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./HomePage.vue?vue&type=template&id=93a843d4&scoped=true&\"\nimport script from \"./HomePage.vue?vue&type=script&lang=js&\"\nexport * from \"./HomePage.vue?vue&type=script&lang=js&\"\nimport style0 from \"./HomePage.vue?vue&type=style&index=0&id=93a843d4&prod&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"93a843d4\",\n  null\n  \n)\n\nexport default component.exports","var render = function render(){var _vm=this,_c=_vm._self._c;return _c('div',{staticClass:\"Experiments w-full h-full\"},[_c('div',{staticClass:\"bg w-full h-20 flex justify-center items-center font-bold text-4xl\"},[_vm._v(\" Experiment Results \")]),_vm._m(0),_c('div',{staticClass:\"w-full h-full flex justify-center items-center\"},[_c('div',{staticClass:\"main\",staticStyle:{\"width\":\"95rem\"}},[_c('div',{staticClass:\"table\"},[_c('ul',{staticStyle:{\"padding-top\":\"20px\"}},[_c('li',{staticClass:\"one\"}),_vm._l((_vm.titles),function(item,index){return _c('li',{key:index,staticClass:\"two\"},[(index == 0)?_c('div',[_c('P',[_vm._v(\"Validation\")]),_c('P',[_vm._v(\"Overall\")])],1):_c('div',[_c('p',[_vm._v(_vm._s(item))])])])})],2),_c('ul',{staticStyle:{\"padding-bottom\":\"10px\"}},[_c('li',{staticClass:\"one\"}),_vm._l((_vm.titles),function(item,index){return _c('li',{key:index,staticClass:\"two\"},[(index == 0)?_c('div',[_vm._m(1,true)]):_c('div',[_c('div',{staticClass:\"name\"},[_c('div',{staticClass:\"details\"},[_c('p',[_vm._v(\"Tiny\")]),_c('p',{staticClass:\"text-xs\",staticStyle:{\"padding-top\":\"5px\"}},[_vm._v(\" ( \"+_vm._s(_vm.details[index].t1)+\" ) \")])]),_c('div',{staticClass:\"details\"},[_c('p',[_vm._v(\"All\")]),_c('p',{staticClass:\"text-xs\",staticStyle:{\"padding-top\":\"5px\"}},[_vm._v(\" ( \"+_vm._s(_vm.details[index].t2)+\" ) \")])])])])])})],2),_c('div',{staticClass:\"table-2\"},_vm._l((_vm.table1),function(item){return _c('ul',{key:item.prop,staticClass:\"row-1\"},[_c('li',{staticClass:\"one\"},[_c('a',{attrs:{\"href\":item.link,\"target\":\"_blank\"}},[_vm._v(_vm._s(item.prop))])]),_vm._l((item.data),function(t,a){return _c('li',{key:a,staticClass:\"two\"},[(a == 0)?_c('div',[_c('div',{staticClass:\"details\"},[_c('p',[_vm._v(_vm._s(item.sorce))])])]):_c('div',[_c('div',{staticClass:\"name\"},[_c('div',{staticClass:\"details\"},[_c('p',[_vm._v(_vm._s(item.data[a].t1))])]),_c('div',{staticClass:\"details\"},[_c('p',[_vm._v(_vm._s(item.data[a].t2))])])])])])})],2)}),0),_c('div',{staticClass:\"title-2\"},[_vm._v(\" Large Multimodal Models (LMMs): Text + Image as Input \")]),_c('div',{staticClass:\"table-2\"},_vm._l((_vm.table2),function(item){return _c('ul',{key:item.prop,staticClass:\"row-1\"},[_c('li',{staticClass:\"one\"},[_c('a',{attrs:{\"href\":item.link,\"target\":\"_blank\"}},[_vm._v(_vm._s(item.prop))])]),_vm._l((item.data),function(t,a){return _c('li',{key:a,staticClass:\"two\"},[(a == 0)?_c('div',[_c('div',{staticClass:\"details\"},[_c('p',[_vm._v(_vm._s(item.sorce))])])]):_c('div',[_c('div',{staticClass:\"name\"},[_c('div',{staticClass:\"details\"},[_c('p',[_vm._v(_vm._s(item.data[a].t1))])]),_c('div',{staticClass:\"details\"},[_c('p',[_vm._v(_vm._s(item.data[a].t2))])])])])])})],2)}),0),_c('div',{staticClass:\"title-2\"},[_vm._v(\" Large Language Models (LLMs): Only Text as Input \")]),_c('div',{staticClass:\"table-2\"},_vm._l((_vm.table3),function(item){return _c('ul',{key:item.prop,staticClass:\"row-1\"},[_c('li',{staticClass:\"one\"},[_c('a',{attrs:{\"href\":item.link,\"target\":\"_blank\"}},[_vm._v(_vm._s(item.prop))])]),_vm._l((item.data),function(t,a){return _c('li',{key:a,staticClass:\"two\"},[(a == 0)?_c('div',[_c('div',{staticClass:\"details\"},[_c('p',[_vm._v(_vm._s(item.sorce))])])]):_c('div',[_c('div',{staticClass:\"name\"},[_c('div',{staticClass:\"details\"},[_c('p',[_vm._v(_vm._s(item.data[a].t1))])]),_c('div',{staticClass:\"details\"},[_c('p',[_vm._v(_vm._s(item.data[a].t2))])])])])])})],2)}),0)])])])])\n}\nvar staticRenderFns = [function (){var _vm=this,_c=_vm._self._c;return _c('div',{staticClass:\"flex justify-center items-center flex-col\"},[_c('div',{staticClass:\"ExTitle text-3xl font-bold p-5 pt-10\"},[_vm._v(\"Leaderboard\")]),_c('div',{staticClass:\"leadContent w-7/12 pb-10 text-justify\"},[_vm._v(\" We evaluate various models including LLMs and LMMs. In each type, we consider both closed- and open-source models. Our evaluation is conducted under a zero-shot setting to assess the capability of models to generate accurate answers without fine-tuning or few-shot demonstrations on our benchmark. For all models, we use the default prompt provided by each model for multi-choice or open QA, if available. If models do not provide prompts for task types in MMMU, we conduct prompt engineering on the validation set and use the most effective prompt for the later zero-shot experiment. \")])])\n},function (){var _vm=this,_c=_vm._self._c;return _c('div',{staticClass:\"details\"},[_c('p',[_vm._v(\"-\")]),_c('p',{staticClass:\"text-xs\",staticStyle:{\"padding-top\":\"5px\"}},[_vm._v(\"( 666 )\")])])\n}]\n\nexport { render, staticRenderFns }","<template>\n  <div class=\"Experiments w-full h-full\">\n    <div\n      class=\"bg w-full h-20 flex justify-center items-center font-bold text-4xl\"\n    >\n      Experiment Results\n    </div>\n    <div class=\"flex justify-center items-center flex-col\">\n      <div class=\"ExTitle text-3xl font-bold p-5 pt-10\">Leaderboard</div>\n      <div class=\"leadContent w-7/12 pb-10 text-justify\">\n        We evaluate various models including LLMs and LMMs. In each type, we\n        consider both closed- and open-source models. Our evaluation is\n        conducted under a zero-shot setting to assess the capability of models\n        to generate accurate answers without fine-tuning or few-shot\n        demonstrations on our benchmark. For all models, we use the default\n        prompt provided by each model for multi-choice or open QA, if available.\n        If models do not provide prompts for task types in MMMU, we conduct\n        prompt engineering on the validation set and use the most effective\n        prompt for the later zero-shot experiment.\n      </div>\n    </div>\n\n    <div class=\"w-full h-full flex justify-center items-center\">\n      <div class=\"main\" style=\"width: 95rem\">\n        <div class=\"table\">\n          <ul style=\"padding-top: 20px\">\n            <li class=\"one\"></li>\n            <li v-for=\"(item, index) in titles\" :key=\"index\" class=\"two\">\n              <div v-if=\"index == 0\">\n                <P>Validation</P>\n                <P>Overall</P>\n              </div>\n              <div v-else>\n                <p>{{ item }}</p>\n              </div>\n            </li>\n          </ul>\n          <ul style=\"padding-bottom: 10px\">\n            <li class=\"one\"></li>\n            <li v-for=\"(item, index) in titles\" :key=\"index\" class=\"two\">\n              <div v-if=\"index == 0\">\n                <div class=\"details\">\n                  <p>-</p>\n                  <p class=\"text-xs\" style=\"padding-top: 5px\">( 666 )</p>\n                </div>\n              </div>\n              <div v-else>\n                <div class=\"name\">\n                  <div class=\"details\">\n                    <p>Tiny</p>\n                    <p class=\"text-xs\" style=\"padding-top: 5px\">\n                      ( {{ details[index].t1 }} )\n                    </p>\n                  </div>\n                  <div class=\"details\">\n                    <p>All</p>\n                    <p class=\"text-xs\" style=\"padding-top: 5px\">\n                      ( {{ details[index].t2 }} )\n                    </p>\n                  </div>\n                </div>\n              </div>\n            </li>\n          </ul>\n\n          <div class=\"table-2\">\n            <ul v-for=\"item in table1\" :key=\"item.prop\" class=\"row-1\">\n              <li class=\"one\">\n                <a :href=\"item.link\" target=\"_blank\">{{ item.prop }}</a>\n              </li>\n              <li v-for=\"(t, a) in item.data\" :key=\"a\" class=\"two\">\n                <div v-if=\"a == 0\">\n                  <div class=\"details\">\n                    <p>{{ item.sorce }}</p>\n                  </div>\n                </div>\n                <div v-else>\n                  <div class=\"name\">\n                    <div class=\"details\">\n                      <p>{{ item.data[a].t1 }}</p>\n                    </div>\n                    <div class=\"details\">\n                      <p>{{ item.data[a].t2 }}</p>\n                    </div>\n                  </div>\n                </div>\n              </li>\n            </ul>\n          </div>\n\n          <div class=\"title-2\">\n            Large Multimodal Models (LMMs): Text + Image as Input\n          </div>\n\n          <div class=\"table-2\">\n            <ul v-for=\"item in table2\" :key=\"item.prop\" class=\"row-1\">\n              <li class=\"one\">\n                <a :href=\"item.link\" target=\"_blank\">{{ item.prop }}</a>\n              </li>\n              <li v-for=\"(t, a) in item.data\" :key=\"a\" class=\"two\">\n                <div v-if=\"a == 0\">\n                  <div class=\"details\">\n                    <p>{{ item.sorce }}</p>\n                  </div>\n                </div>\n                <div v-else>\n                  <div class=\"name\">\n                    <div class=\"details\">\n                      <p>{{ item.data[a].t1 }}</p>\n                    </div>\n                    <div class=\"details\">\n                      <p>{{ item.data[a].t2 }}</p>\n                    </div>\n                  </div>\n                </div>\n              </li>\n            </ul>\n          </div>\n\n          <div class=\"title-2\">\n            Large Language Models (LLMs): Only Text as Input\n          </div>\n\n          <div class=\"table-2\">\n            <ul v-for=\"item in table3\" :key=\"item.prop\" class=\"row-1\">\n              <li class=\"one\">\n                <a :href=\"item.link\" target=\"_blank\">{{ item.prop }}</a>\n              </li>\n              <li v-for=\"(t, a) in item.data\" :key=\"a\" class=\"two\">\n                <div v-if=\"a == 0\">\n                  <div class=\"details\">\n                    <p>{{ item.sorce }}</p>\n                  </div>\n                </div>\n                <div v-else>\n                  <div class=\"name\">\n                    <div class=\"details\">\n                      <p>{{ item.data[a].t1 }}</p>\n                    </div>\n                    <div class=\"details\">\n                      <p>{{ item.data[a].t2 }}</p>\n                    </div>\n                  </div>\n                </div>\n              </li>\n            </ul>\n          </div>\n        </div>\n      </div>\n    </div>\n  </div>\n</template>\n\n<script>\nexport default {\n  data() {\n    return {\n      headers: [\n        \"Validation Overall\",\n        \"Test Overall\",\n        \"WebPathology\",\n        \"Twitter\",\n        \"Youtube\",\n        \"Book\",\n      ], // 你的表头数据\n      tableData: [\n        // 你的表格数据，每个数组表示一行，每个子数组表示单元格\n        [\"Random Choice\", 25.1, 25.8, 25.2, 24.7, 25.9, 25.5],\n        [\"Frequent Choice\", 29.1, 27.5, 25.8, 27.7, 30.2, 28.4],\n        // ... 更多行\n      ],\n      titles: [\n        \"Validation\",\n        \"Test Overall\",\n        \"WebPathology\",\n        \"Twitter\",\n        \"Youtube\",\n        \"Book\",\n      ],\n      details: [\n        {\n          t1: 3445,\n          t2: 4667,\n        },\n        {\n          t1: 3445,\n          t2: 4667,\n        },\n        {\n          t1: 3445,\n          t2: 4667,\n        },\n        {\n          t1: 3445,\n          t2: 4667,\n        },\n        {\n          t1: 3445,\n          t2: 4667,\n        },\n        {\n          t1: 3445,\n          t2: 4667,\n        },\n      ],\n      table1: [\n        {\n          prop: \"Random Choice\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"Frequent Choice\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 22.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"Expert performance\",\n          link: \"https://www.baidu.com/\",\n          sorce: \"34.1\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 23.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n      ],\n      table2: [\n        {\n          prop: \"OpenFlamingo2-9B\",\n          link: \"https://www.baidu.com/\",\n          sorce: \"34.1\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"Kosmos2\",\n          link: \"https://www.baidu.com/\",\n          sorce: \"34.1\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"Fuyu-8B\",\n          link: \"https://www.baidu.com/\",\n          sorce: \"34.1\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"MiniGPT4-Vicuna-13B\",\n          link: \"https://www.baidu.com/\",\n          sorce: \"34.1\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"LLaMA-Adapter2-7B\",\n          link: \"https://www.baidu.com/\",\n          sorce: \"34.1\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"Otter\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"CogVLM\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"BLIP-2 FLAN-T5-XL\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"BLIP-2 FLAN-T5-XXL\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"Owen-VL-7B\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"LLaVA-1.5-7B\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"LLaVA-1.5-13B\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"InstructBLIP-T5-XL\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"InstructBLIP-TS-XXL\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"Qwen-VL-PLUS\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"Gemini Pro Vision\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"GPT-4V\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n      ],\n\n      table3: [\n        {\n          prop: \" Vicuna-v1.5-13B\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"GPT-4 Turbo\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"GPT-3.5 Turbo\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"Gemini Pro\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n        {\n          prop: \"ERNIE-Bot 4.0\",\n          sorce: \"34.1\",\n          link: \"https://www.baidu.com/\",\n          data: [\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n            {\n              t1: 25.1,\n              t2: 29.4,\n            },\n          ],\n        },\n      ],\n    };\n  },\n};\n</script>\n\n<style scoped lang=\"less\">\n.Experiments {\n  .bg {\n    background-color: #f5f5f5;\n    color: rgba(0, 0, 0, 0.7);\n  }\n\n  .table {\n    margin: 10px;\n    border-top: 4px solid #000;\n    border-bottom: 4px solid #000;\n    width: 100%;\n  }\n\n  .one {\n    flex: 1;\n  }\n  .one:hover {\n    color: rgb(119, 119, 196);\n  }\n  ul {\n    display: flex;\n    width: 100%;\n    list-style-type: none;\n    flex-flow: wrap;\n  }\n  .two {\n    flex: 1;\n    text-align: center;\n    display: flex;\n    flex-direction: column;\n\n    font-size: 24px;\n    font-family: Arial, sans-serif;\n    font-weight: bold;\n  }\n  .three {\n    flex: 1;\n    text-align: center;\n    font-size: 20px;\n    font-family: Arial, sans-serif;\n    display: flex;\n    justify-content: space-around;\n    align-items: center;\n  }\n  .name {\n    display: flex;\n    justify-content: space-around;\n  }\n  .details {\n    width: 100%;\n    font-size: 20px;\n    font-weight: 400;\n    bottom: 0;\n  }\n  .table-2 {\n    border-top: 2px solid #000;\n    border-bottom: 2px solid #000;\n    padding: 10px 0;\n  }\n  .row-1 {\n    display: flex;\n    font-size: 20px;\n  }\n  .title-2 {\n    display: flex;\n    justify-content: center;\n    align-items: center;\n    font-size: 24px;\n    font-family: Arial, sans-serif;\n    font-weight: bold;\n    padding: 20px;\n  }\n  a {\n    // text-decoration: none;\n  }\n}\n</style>\n","import mod from \"-!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./ExperimentsPage.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./ExperimentsPage.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./ExperimentsPage.vue?vue&type=template&id=2976c640&scoped=true&\"\nimport script from \"./ExperimentsPage.vue?vue&type=script&lang=js&\"\nexport * from \"./ExperimentsPage.vue?vue&type=script&lang=js&\"\nimport style0 from \"./ExperimentsPage.vue?vue&type=style&index=0&id=2976c640&prod&scoped=true&lang=less&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"2976c640\",\n  null\n  \n)\n\nexport default component.exports","var render = function render(){var _vm=this,_c=_vm._self._c;return _vm._m(0)\n}\nvar staticRenderFns = [function (){var _vm=this,_c=_vm._self._c;return _c('div',{staticClass:\"w-full h-full pt-5\"},[_c('div',{staticClass:\"PageContent flex justify-center items-center flex-col\"},[_c('div',{staticClass:\"headtitle text-3xl font-bold p-5\"},[_vm._v(\" Robustness Evaluation of LMMs towards Image Corruption \")]),_c('div',{staticClass:\"overview_content w-7/12 text-justify\"},[_c('div',[_vm._v(\" In the realm of practical pathology, the interpretation of mod404 els significantly influences the subsequent medical decisions and treatment strategies doctors determine. Therefore, the ro406 bustness of these models is crucial for clinical applications. Given that during staining, scanning, or image generation of pathological slides, several factors often affect image quality, including JPEG compression, pixelation, blur(encompasses bubble blur, defocus blur, motion blur), and color variations (such as brightness, saturation, and hue). Inspired by the analysis of encoder-based models’ robustness against pathol413 ogy image corruption [Zheng et al., 2024; Sun et al., 2023a; Zhang et al., 2022], we incorporate these corruptions to ex415 plore the robustness of LMMs against these corruptions on PathMMU dataset. \")]),_c('img',{staticClass:\"pt-10 pb-2\",attrs:{\"src\":\"resources/img/figures/corruption_illustration.png\",\"alt\":\"\"}}),_c('img',{staticClass:\"pt-10 pb-2\",attrs:{\"src\":\"resources/img/figures/attribute.png\",\"alt\":\"\"}}),_c('div',{staticClass:\"pb-10\"},[_vm._v(\" Figure 5: Illustration of the model’s performance towards different levels of color-related (brightness, hue, saturation) and image quality-related (pixelation, JPEG compression, bubble effect, motion blur, defocus) corruptions on the PathMMU test-tiny set, where level 0 represents the model’s performance without any corruption. \")])])]),_c('div',{staticClass:\"PageContent flex justify-center items-center flex-col\"},[_c('div',{staticClass:\"headtitle text-3xl font-bold p-5\"},[_vm._v(\"Attributes all\")]),_c('div',{staticClass:\"overview_content w-7/12\"},[_c('img',{staticClass:\"pt-10 pb-2\",attrs:{\"src\":\"resources/img/figures/attribute_all.png\",\"alt\":\"\"}}),_c('img',{staticClass:\"pt-10 pb-2\",attrs:{\"src\":\"resources/img/figures/attribute_half.png\",\"alt\":\"\"}}),_c('div',{staticClass:\"pb-10\"},[_vm._v(\" Figure 5: Illustration of the model’s performance towards different levels of color-related (brightness, hue, saturation) and image quality-related (pixelation, JPEG compression, bubble effect, motion blur, defocus) corruptions on the PathMMU test-tiny set, where level 0 represents the model’s performance without any corruption. \")])])])])\n}]\n\nexport { render, staticRenderFns }","<template>\n  <div class=\"w-full h-full pt-5\">\n    <!-- Comparisons  -->\n    <div class=\"PageContent flex justify-center items-center flex-col\">\n      <!-- overview -->\n      <div class=\"headtitle text-3xl font-bold p-5\">\n        Robustness Evaluation of LMMs towards Image Corruption\n      </div>\n      <div class=\"overview_content w-7/12 text-justify\">\n        <div>\n          In the realm of practical pathology, the interpretation of mod404 els\n          significantly influences the subsequent medical decisions and\n          treatment strategies doctors determine. Therefore, the ro406 bustness\n          of these models is crucial for clinical applications. Given that\n          during staining, scanning, or image generation of pathological slides,\n          several factors often affect image quality, including JPEG\n          compression, pixelation, blur(encompasses bubble blur, defocus blur,\n          motion blur), and color variations (such as brightness, saturation,\n          and hue). Inspired by the analysis of encoder-based models’ robustness\n          against pathol413 ogy image corruption [Zheng et al., 2024; Sun et\n          al., 2023a; Zhang et al., 2022], we incorporate these corruptions to\n          ex415 plore the robustness of LMMs against these corruptions on\n          PathMMU dataset.\n        </div>\n        <img\n          src=\"resources/img/figures/corruption_illustration.png\"\n          class=\"pt-10 pb-2\"\n          alt=\"\"\n        />\n        <img\n          src=\"resources/img/figures/attribute.png\"\n          class=\"pt-10 pb-2\"\n          alt=\"\"\n        />\n        <div class=\"pb-10\">\n          Figure 5: Illustration of the model’s performance towards different\n          levels of color-related (brightness, hue, saturation) and image\n          quality-related (pixelation, JPEG compression, bubble effect, motion\n          blur, defocus) corruptions on the PathMMU test-tiny set, where level 0\n          represents the model’s performance without any corruption.\n        </div>\n      </div>\n    </div>\n    <!-- attributes all -->\n    <div class=\"PageContent flex justify-center items-center flex-col\">\n      <!-- overview -->\n      <div class=\"headtitle text-3xl font-bold p-5\">Attributes all</div>\n      <div class=\"overview_content w-7/12\">\n        <img\n          src=\"resources/img/figures/attribute_all.png\"\n          class=\"pt-10 pb-2\"\n          alt=\"\"\n        />\n        <img\n          src=\"resources/img/figures/attribute_half.png\"\n          class=\"pt-10 pb-2\"\n          alt=\"\"\n        />\n        <div class=\"pb-10\">\n          Figure 5: Illustration of the model’s performance towards different\n          levels of color-related (brightness, hue, saturation) and image\n          quality-related (pixelation, JPEG compression, bubble effect, motion\n          blur, defocus) corruptions on the PathMMU test-tiny set, where level 0\n          represents the model’s performance without any corruption.\n        </div>\n      </div>\n    </div>\n  </div>\n</template>\n\n<script>\nexport default {};\n</script>\n\n<style scoped>\n.bg {\n  background-color: #f5f5f5;\n  color: rgba(0, 0, 0, 0.7);\n}\n.FeatureTitle {\n  color: #6f6e6e;\n  font-size: 27px;\n}\n.SubTitle {\n  color: #6f6e6e;\n  margin-top: 20px;\n  font-size: 20px;\n}\n.subContent {\n  font-size: 16px;\n  color: #6f6e6e;\n}\n</style>\n","import mod from \"-!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./ThirdPart.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./ThirdPart.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./ThirdPart.vue?vue&type=template&id=8310e544&scoped=true&\"\nimport script from \"./ThirdPart.vue?vue&type=script&lang=js&\"\nexport * from \"./ThirdPart.vue?vue&type=script&lang=js&\"\nimport style0 from \"./ThirdPart.vue?vue&type=style&index=0&id=8310e544&prod&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"8310e544\",\n  null\n  \n)\n\nexport default component.exports","var render = function render(){var _vm=this,_c=_vm._self._c;return _vm._m(0)\n}\nvar staticRenderFns = [function (){var _vm=this,_c=_vm._self._c;return _c('div',{staticClass:\"FooterPart w-full h-56 flex justify-center items-center text-base\",staticStyle:{\"background-color\":\"#fafafa\"}},[_c('p',[_vm._v(\" This website is website adapted from \"),_c('a',{attrs:{\"href\":\"https://nerfies.github.io/\"}},[_vm._v(\"Nerfies\")]),_vm._v(\" and \"),_c('a',{attrs:{\"href\":\"https://mathvista.github.io/\"}},[_vm._v(\"MathVista\")]),_vm._v(\", licensed under a \"),_c('a',{attrs:{\"rel\":\"license\",\"href\":\"http://creativecommons.org/licenses/by-sa/4.0/\"}},[_vm._v(\"Creative Commons Attribution-ShareAlike 4.0 International License\")]),_vm._v(\". \")])])\n}]\n\nexport { render, staticRenderFns }","<template>\n  <div\n    class=\"FooterPart w-full h-56 flex justify-center items-center text-base\"\n    style=\"background-color: #fafafa\"\n  >\n    <p>\n      This website is website adapted from\n      <a href=\"https://nerfies.github.io/\">Nerfies</a> and\n      <a href=\"https://mathvista.github.io/\">MathVista</a>, licensed under a\n      <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"\n        >Creative Commons Attribution-ShareAlike 4.0 International License</a\n      >.\n    </p>\n  </div>\n</template>\n\n<script>\nexport default {};\n</script>\n\n<style></style>\n","import mod from \"-!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./FooterPart.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./FooterPart.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./FooterPart.vue?vue&type=template&id=6478c49e&\"\nimport script from \"./FooterPart.vue?vue&type=script&lang=js&\"\nexport * from \"./FooterPart.vue?vue&type=script&lang=js&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports","<template>\n  <div class=\"HomePage h-full w-full text-lg\">\n    <!-- <el-dropdown>\n      <span class=\"el-dropdown-link text-center\">\n        下拉菜单<i class=\"el-icon-arrow-down el-icon--right\"></i>\n      </span>\n      <el-dropdown-menu slot=\"dropdown\">\n        <el-dropdown-item>黄金糕</el-dropdown-item>\n        <el-dropdown-item>狮子头</el-dropdown-item>\n        <el-dropdown-item>螺蛳粉</el-dropdown-item>\n        <el-dropdown-item disabled>双皮奶</el-dropdown-item>\n        <el-dropdown-item divided>蚵仔煎</el-dropdown-item>\n      </el-dropdown-menu>\n    </el-dropdown> -->\n    <!-- top -->\n    <TopMenu ref=\"TopMenu\"></TopMenu>\n    <!-- HomePage -->\n    <HomePage></HomePage>\n    <!-- Experiments -->\n    <ExperimentsPage></ExperimentsPage>\n    <!-- ThirdPart -->\n    <ThirdPart></ThirdPart>\n    <!-- FooterPart -->\n    <FooterPart></FooterPart>\n  </div>\n</template>\n\n<script>\n// @ is an alias to /src\nimport TopMenu from \"@/components/TopMenu.vue\";\nimport HomePage from \"@/components/HomePage.vue\";\nimport ExperimentsPage from \"@/components/ExperimentsPage.vue\";\nimport ThirdPart from \"@/components/ThirdPart.vue\";\nimport FooterPart from \"@/components/FooterPart.vue\";\n\nexport default {\n  name: \"HomeView\",\n  components: {\n    TopMenu,\n    HomePage,\n    ExperimentsPage,\n    ThirdPart,\n    FooterPart,\n  },\n  data() {\n    return {};\n  },\n  mounted() {},\n  methods: {\n    // changeTopMenu() {\n    //   let topMenu = this.$refs.TopMenu.$refs.topItem;\n    //   // 监听滚动事件\n    //   window.addEventListener(\"scroll\", function () {\n    //     // 页面可视区域的高度\n    //     const windowHeight = window.innerHeight;\n    //     // 整个页面的高度（包括滚动部分）\n    //     const documentHeight = document.documentElement.scrollHeight;\n    //     // 当前滚动位置\n    //     const scrollPosition = window.scrollY;\n    //     // 如果滚动到页面底部\n    //     if (scrollPosition + windowHeight >= documentHeight) {\n    //       // 修改背景颜色为黑色\n    //       topMenu.style.transition = `0.5s`;\n    //       topMenu.style.backgroundColor = \"rgba(0, 0, 0, 1)\";\n    //     } else {\n    //       // 否则背景颜色为透明\n    //       topMenu.style.transition = `0.5s`;\n    //       topMenu.style.backgroundColor = \"transparent\";\n    //     }\n    //   });\n    // },\n  },\n};\n</script>\n\n<style>\n.el-dropdown-link {\n  cursor: pointer;\n  color: #409eff;\n}\n.el-icon-arrow-down {\n  font-size: 12px;\n}\n</style>\n","import mod from \"-!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./HomeView.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./HomeView.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./HomeView.vue?vue&type=template&id=57a570b4&\"\nimport script from \"./HomeView.vue?vue&type=script&lang=js&\"\nexport * from \"./HomeView.vue?vue&type=script&lang=js&\"\nimport style0 from \"./HomeView.vue?vue&type=style&index=0&id=57a570b4&prod&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports","import Vue from \"vue\";\nimport VueRouter from \"vue-router\";\nimport HomeView from \"../views/HomeView.vue\";\n\nVue.use(VueRouter);\n\nconst routes = [\n  {\n    path: \"/\",\n    name: \"home\",\n    component: HomeView,\n  },\n];\n\nconst router = new VueRouter({\n  mode: \"hash\",\n  base: process.env.BASE_URL,\n  routes,\n});\n\nexport default router;\n","import \"@/assets/css/styles.css\";\nimport ElementUI from \"element-ui\";\nimport \"element-ui/lib/theme-chalk/index.css\";\nimport Vue from \"vue\";\nimport App from \"./App.vue\";\nimport router from \"./router\";\n\nVue.use(ElementUI);\nVue.config.productionTip = false;\n\nnew Vue({\n  router,\n  render: function (h) {\n    return h(App);\n  },\n}).$mount(\"#app\");\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\tid: moduleId,\n\t\tloaded: false,\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Flag the module as loaded\n\tmodule.loaded = true;\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n","__webpack_require__.amdO = {};","var deferred = [];\n__webpack_require__.O = function(result, chunkIds, fn, priority) {\n\tif(chunkIds) {\n\t\tpriority = priority || 0;\n\t\tfor(var i = deferred.length; i > 0 && deferred[i - 1][2] > priority; i--) deferred[i] = deferred[i - 1];\n\t\tdeferred[i] = [chunkIds, fn, priority];\n\t\treturn;\n\t}\n\tvar notFulfilled = Infinity;\n\tfor (var i = 0; i < deferred.length; i++) {\n\t\tvar chunkIds = deferred[i][0];\n\t\tvar fn = deferred[i][1];\n\t\tvar priority = deferred[i][2];\n\t\tvar fulfilled = true;\n\t\tfor (var j = 0; j < chunkIds.length; j++) {\n\t\t\tif ((priority & 1 === 0 || notFulfilled >= priority) && Object.keys(__webpack_require__.O).every(function(key) { return __webpack_require__.O[key](chunkIds[j]); })) {\n\t\t\t\tchunkIds.splice(j--, 1);\n\t\t\t} else {\n\t\t\t\tfulfilled = false;\n\t\t\t\tif(priority < notFulfilled) notFulfilled = priority;\n\t\t\t}\n\t\t}\n\t\tif(fulfilled) {\n\t\t\tdeferred.splice(i--, 1)\n\t\t\tvar r = fn();\n\t\t\tif (r !== undefined) result = r;\n\t\t}\n\t}\n\treturn result;\n};","// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = function(module) {\n\tvar getter = module && module.__esModule ?\n\t\tfunction() { return module['default']; } :\n\t\tfunction() { return module; };\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};","// define getter functions for harmony exports\n__webpack_require__.d = function(exports, definition) {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.g = (function() {\n\tif (typeof globalThis === 'object') return globalThis;\n\ttry {\n\t\treturn this || new Function('return this')();\n\t} catch (e) {\n\t\tif (typeof window === 'object') return window;\n\t}\n})();","__webpack_require__.o = function(obj, prop) { return Object.prototype.hasOwnProperty.call(obj, prop); }","// define __esModule on exports\n__webpack_require__.r = function(exports) {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","__webpack_require__.nmd = function(module) {\n\tmodule.paths = [];\n\tif (!module.children) module.children = [];\n\treturn module;\n};","// no baseURI\n\n// object to store loaded and loading chunks\n// undefined = chunk not loaded, null = chunk preloaded/prefetched\n// [resolve, reject, Promise] = chunk loading, 0 = chunk loaded\nvar installedChunks = {\n\t143: 0\n};\n\n// no chunk on demand loading\n\n// no prefetching\n\n// no preloaded\n\n// no HMR\n\n// no HMR manifest\n\n__webpack_require__.O.j = function(chunkId) { return installedChunks[chunkId] === 0; };\n\n// install a JSONP callback for chunk loading\nvar webpackJsonpCallback = function(parentChunkLoadingFunction, data) {\n\tvar chunkIds = data[0];\n\tvar moreModules = data[1];\n\tvar runtime = data[2];\n\t// add \"moreModules\" to the modules object,\n\t// then flag all \"chunkIds\" as loaded and fire callback\n\tvar moduleId, chunkId, i = 0;\n\tif(chunkIds.some(function(id) { return installedChunks[id] !== 0; })) {\n\t\tfor(moduleId in moreModules) {\n\t\t\tif(__webpack_require__.o(moreModules, moduleId)) {\n\t\t\t\t__webpack_require__.m[moduleId] = moreModules[moduleId];\n\t\t\t}\n\t\t}\n\t\tif(runtime) var result = runtime(__webpack_require__);\n\t}\n\tif(parentChunkLoadingFunction) parentChunkLoadingFunction(data);\n\tfor(;i < chunkIds.length; i++) {\n\t\tchunkId = chunkIds[i];\n\t\tif(__webpack_require__.o(installedChunks, chunkId) && installedChunks[chunkId]) {\n\t\t\tinstalledChunks[chunkId][0]();\n\t\t}\n\t\tinstalledChunks[chunkId] = 0;\n\t}\n\treturn __webpack_require__.O(result);\n}\n\nvar chunkLoadingGlobal = self[\"webpackChunkportfolio\"] = self[\"webpackChunkportfolio\"] || [];\nchunkLoadingGlobal.forEach(webpackJsonpCallback.bind(null, 0));\nchunkLoadingGlobal.push = webpackJsonpCallback.bind(null, chunkLoadingGlobal.push.bind(chunkLoadingGlobal));","// startup\n// Load entry module and return exports\n// This entry module depends on other loaded chunks and execution need to be delayed\nvar __webpack_exports__ = __webpack_require__.O(undefined, [998], function() { return __webpack_require__(7060); })\n__webpack_exports__ = __webpack_require__.O(__webpack_exports__);\n"],"names":["render","_vm","this","_c","_self","attrs","staticRenderFns","script","component","staticClass","ref","_m","_v","staticStyle","data","publicUrl","topMenu","content","id","_l","item","index","key","_s","details","t1","t2","prop","link","t","a","sorce","headers","tableData","titles","table1","table2","table3","name","components","TopMenu","HomePage","ExperimentsPage","ThirdPart","FooterPart","mounted","methods","use","routes","path","HomeView","router","mode","base","config","productionTip","h","App","$mount","__webpack_module_cache__","__webpack_require__","moduleId","cachedModule","undefined","exports","module","loaded","__webpack_modules__","m","amdO","deferred","O","result","chunkIds","fn","priority","notFulfilled","Infinity","i","length","fulfilled","j","Object","keys","every","splice","r","n","getter","__esModule","d","definition","o","defineProperty","enumerable","get","g","globalThis","Function","e","window","obj","prototype","hasOwnProperty","call","Symbol","toStringTag","value","nmd","paths","children","installedChunks","chunkId","webpackJsonpCallback","parentChunkLoadingFunction","moreModules","runtime","some","chunkLoadingGlobal","self","forEach","bind","push","__webpack_exports__"],"sourceRoot":""}